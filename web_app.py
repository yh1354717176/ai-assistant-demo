import os
import base64
from dotenv import load_dotenv

# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient
from langchain_core.tools import tool
from langchain_core.tools.retriever import create_retriever_tool
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from typing import Annotated, TypedDict
# æ–°å¢è¿™ä¸€è¡Œï¼Œå¼•å…¥ DuckDuckGo æœç´¢å·¥å…·
from langchain_community.tools import DuckDuckGoSearchRun
# æ–°å¢è¿™ä¸€è¡Œ
from langchain_community.agent_toolkits import GmailToolkit
from langchain_google_community import CalendarToolkit 
# from googleapiclient.discovery import build # Removed as we use Toolkit
# import datetime # Removed as we use Toolkit (standard lib datetime might be needed by other parts, but let's check. lines 307 usages import it locally or use global? Global usage was added by me. I'll remove it. If other code needs it, I'll keep it. Wait, line 307 imports it inside tool_calls logic? No, line 307 is "import datetime". So global import is safe to remove if that was the only global one.)


# 1. æ¢å¤ç¯å¢ƒå˜é‡ (API Key & Tracing)
# åªè¦ Secrets é‡Œæœ‰çš„é…ç½®ï¼Œéƒ½è‡ªåŠ¨åŠ è½½åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­
# è¿™æ ·ä¸ä»…æ”¯æŒ Google Keyï¼Œä¹Ÿæ”¯æŒ LangSmith çš„é…ç½®
# æ³¨æ„ï¼šæ’é™¤ JSON æ ¼å¼çš„ secrets
json_secrets = ["credentials_json", "token_json"]
for key in st.secrets:
    if key not in json_secrets:
        os.environ[key] = st.secrets[key]

import json  # æå‰å¯¼å…¥ json æ¨¡å—

# æ¢å¤ credentials.json
if "credentials_json" in st.secrets:
    cred_content = st.secrets["credentials_json"].strip()  # å»é™¤å‰åç©ºç™½å’Œæ¢è¡Œç¬¦
    try:
        json.loads(cred_content)  # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆ JSON
        with open("credentials.json", "w") as f:
            f.write(cred_content)
    except json.JSONDecodeError as e:
        st.error(f"âŒ credentials_json æ ¼å¼é”™è¯¯: {e}")

# æ¢å¤ token.json
if "token_json" in st.secrets:
    token_content = st.secrets["token_json"].strip()  # å»é™¤å‰åç©ºç™½å’Œæ¢è¡Œç¬¦
    # éªŒè¯ JSON æ ¼å¼æ˜¯å¦æ­£ç¡®
    try:
        json.loads(token_content)  # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆ JSON
        with open("token.json", "w") as f:
            f.write(token_content)
    except json.JSONDecodeError as e:
        st.error(f"âŒ token_json æ ¼å¼é”™è¯¯: {e}")

# â˜ï¸ äº‘ç«¯éƒ¨ç½²è¡¥ä¸ (End)

# ==========================================
# 1. é¡µé¢é…ç½® & æ ‡é¢˜
# ==========================================
st.set_page_config(page_title="å¹»å½±ç§‘æŠ€ AI åŠ©æ‰‹", page_icon="ğŸ¤–")
st.title("ğŸ¤– å¹»å½±ç§‘æŠ€å‘˜å·¥åŠ©æ‰‹ (Agentç‰ˆ v5.0)")
st.caption("æˆ‘æ˜¯ç”± LangGraph é©±åŠ¨çš„æ™ºèƒ½ä½“ï¼Œèƒ½æŸ¥æ–‡æ¡£ï¼Œä¹Ÿèƒ½ç®—å·¥èµ„ã€‚")


# ==========================================
# 2. ç¼“å­˜èµ„æº (é¿å…æ¯æ¬¡åˆ·æ–°éƒ½é‡è¿æ•°æ®åº“)
# ==========================================
@st.cache_resource
def get_graph(_version="v5.1"):  # ä¿®æ”¹ç‰ˆæœ¬å·å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    """åˆå§‹åŒ–å›¾ç»“æ„ï¼Œåªæ‰§è¡Œä¸€æ¬¡"""
    print(f"ğŸ”„ æ­£åœ¨åˆå§‹åŒ– LangGraph... (Cache Version: {_version})")

    # --- æ¨¡å‹ä¸æ•°æ®åº“ ---
    llm = ChatGoogleGenerativeAI(model="gemini-3-flash-preview")  # ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹
    embeddings = GoogleGenerativeAIEmbeddings(model="gemini-embedding-001")

    # Qdrant è¿æ¥é…ç½® (æ”¯æŒæœ¬åœ°å’Œäº‘ç«¯)
    qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")
    qdrant_api_key = os.getenv("QDRANT_API_KEY", None)
    
    if qdrant_api_key:
        # ä½¿ç”¨ Qdrant Cloud
        client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)
    else:
        # ä½¿ç”¨æœ¬åœ° Qdrant
        client = QdrantClient(url=qdrant_url)
    
    vectorstore = QdrantVectorStore(
        client=client,
        collection_name="knowledge_base",
        embedding=embeddings
    )
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

    # --- å·¥å…·å®šä¹‰ ---
    retriever_tool = create_retriever_tool(
        retriever,
        name="search_company_policy",
        description="æŸ¥è¯¢å…³äº'å¹»å½±ç§‘æŠ€'çš„å…¬å¸è§„å®šã€ç¦åˆ©ç­‰ã€‚"
    )

    @tool
    def calculate_bonus(salary: int) -> str:
        """æ ¹æ®å·¥èµ„è®¡ç®—å¹´ç»ˆå¥–ã€‚"""
        bonus = salary * 0.2
        return f"ã€ç³»ç»Ÿè®¡ç®—ã€‘æ ¹æ®æ‚¨çš„å·¥èµ„ï¼Œå¹´ç»ˆå¥–åº”ä¸º {bonus} å…ƒã€‚"

    # åˆå§‹åŒ–æœç´¢å·¥å…·
    search_tool = DuckDuckGoSearchRun()

    # åˆå§‹åŒ– Gmail å·¥å…·ç®±
    # å®ƒä¼šè‡ªåŠ¨è¯»å–æ–‡ä»¶å¤¹é‡Œçš„ token.json
    gmail_toolkit = GmailToolkit()
    
    # åˆå§‹åŒ– Calendar å·¥å…·ç®±
    # ç›´æ¥ä» token.json åŠ è½½å·²è®¤è¯çš„å‡­è¯ï¼Œé¿å…åœ¨äº‘ç«¯è§¦å‘ OAuth æµç¨‹
    from google.oauth2.credentials import Credentials
    calendar_creds = Credentials.from_authorized_user_file(
        "token.json",
        scopes=["https://www.googleapis.com/auth/calendar"]
    )
    calendar_toolkit = CalendarToolkit(credentials=calendar_creds)

    tools = [retriever_tool, calculate_bonus, search_tool] + gmail_toolkit.get_tools() + calendar_toolkit.get_tools()
    llm_with_tools = llm.bind_tools(tools)

    # --- æ„å»ºå›¾ ---
    class State(TypedDict):
        messages: Annotated[list, add_messages]

    # ç³»ç»Ÿæç¤ºè¯ï¼šæŒ‡å¯¼ AI çš„è¡Œä¸º
    from langchain_core.messages import SystemMessage
    SYSTEM_PROMPT = """ä½ æ˜¯"å¹»å½±ç§‘æŠ€"å…¬å¸çš„æ™ºèƒ½å‘˜å·¥åŠ©æ‰‹ã€‚

è¯·éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. å½“ä½ ä½¿ç”¨å·¥å…·è·å–ä¿¡æ¯åï¼Œå¿…é¡»ç”¨ç®€æ´çš„è‡ªç„¶è¯­è¨€å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
2. ä¸è¦ç›´æ¥å¤è¿°å·¥å…·è¿”å›çš„åŸå§‹å†…å®¹ï¼Œè€Œæ˜¯æç‚¼å…³é”®ä¿¡æ¯ã€‚
3. å›ç­”è¦å‹å¥½ã€ç®€æ´ã€ç›´æ¥ã€‚

å…³äºæ—¥å†å·¥å…·çš„ä½¿ç”¨ï¼š
- å½“ç”¨æˆ·è¯¢é—®"æ—¥ç¨‹"ã€"å®‰æ’"ã€"ä¼šè®®"æ—¶ï¼Œä½¿ç”¨ search_events å·¥å…·æŸ¥è¯¢æ—¥å†äº‹ä»¶
- search_events å·¥å…·å¯ä»¥é€šè¿‡ query å‚æ•°æœç´¢äº‹ä»¶ï¼Œå¯ä»¥é€šè¿‡ min_datetime å’Œ max_datetime è¿‡æ»¤æ—¶é—´èŒƒå›´
- å¯¹äº"æ˜å¤©"ã€"ä¸‹å‘¨"ç­‰æ—¶é—´ç›¸å…³çš„æŸ¥è¯¢ï¼Œè¯·åŠ¡å¿…è‡ªè¡Œè®¡ç®—å¥½ 'YYYY-MM-DD HH:MM:SS' æ ¼å¼çš„ min_datetime å’Œ max_datetime ä¼ ç»™å·¥å…·
- å¯ä»¥ç”¨ get_current_datetime å…ˆè·å–å½“å‰æ—¶é—´ï¼Œå†è¿›è¡Œè®¡ç®—
- å°†æŸ¥è¯¢ç»“æœç”¨å‹å¥½çš„ä¸­æ–‡æ ¼å¼å‘ˆç°ï¼Œå¦‚"æ‚¨æœ‰ä»¥ä¸‹å®‰æ’ï¼š..."
- å¦‚æœæ²¡æœ‰æ—¥ç¨‹ï¼Œå›å¤"æ‚¨æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ—¥ç¨‹"
"""

    def chatbot(state: State):
        messages = state["messages"]
        # ç¡®ä¿ç³»ç»Ÿæç¤ºè¯åœ¨æ¶ˆæ¯åˆ—è¡¨æœ€å‰é¢
        if not messages or not isinstance(messages[0], SystemMessage):
            messages = [SystemMessage(content=SYSTEM_PROMPT)] + list(messages)
        return {"messages": [llm_with_tools.invoke(messages)]}

    graph_builder = StateGraph(State)
    graph_builder.add_node("chatbot", chatbot)
    graph_builder.add_node("tools", ToolNode(tools=tools))

    graph_builder.add_edge(START, "chatbot")
    graph_builder.add_conditional_edges("chatbot", tools_condition)
    graph_builder.add_edge("tools", "chatbot")

    # ç¼–è¯‘å›¾ (å¸¦è®°å¿†)
    memory = MemorySaver()
    graph = graph_builder.compile(checkpointer=memory)
    return graph


# åŠ è½½å›¾
graph = get_graph()

# ==========================================
# 3. ä¼šè¯çŠ¶æ€ç®¡ç† (Session State)
# ==========================================
# Streamlit æ¯æ¬¡äº¤äº’éƒ½ä¼šé‡è·‘ä»£ç ï¼Œæ‰€ä»¥è¦ç”¨ session_state å­˜èŠå¤©è®°å½•

if "messages" not in st.session_state:
    st.session_state["messages"] = []

# å­˜å‚¨å·¥å…·è°ƒç”¨å†å²
if "tool_calls" not in st.session_state:
    st.session_state["tool_calls"] = []

if "thread_id" not in st.session_state:
    # ç»™æ¯ä¸ªç”¨æˆ·ç”Ÿæˆä¸€ä¸ªéšæœº IDï¼Œæˆ–è€…å›ºå®šä¸€ä¸ªæ–¹ä¾¿æµ‹è¯•
    import uuid

    st.session_state["thread_id"] = str(uuid.uuid4())

# å­˜å‚¨ä¸Šä¼ çš„å›¾ç‰‡
if "uploaded_image" not in st.session_state:
    st.session_state["uploaded_image"] = None

# ==========================================
# 4. æ¸²æŸ“èŠå¤©ç•Œé¢
# ==========================================

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state["messages"]:
    # åŒºåˆ†æ˜¯ç”¨æˆ·è¿˜æ˜¯ AI
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        st.chat_message("assistant").write(msg["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if user_input := st.chat_input("è¯·è¾“å…¥é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šå…¬å¸å‰ç¥¥ç‰©å«ä»€ä¹ˆï¼Ÿï¼‰"):
    # 1. æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user").write(user_input)
    
    # å¦‚æœæœ‰ä¸Šä¼ çš„å›¾ç‰‡ï¼Œä¹Ÿæ˜¾ç¤ºå‡ºæ¥
    if st.session_state["uploaded_image"]:
        st.chat_message("user").image(st.session_state["uploaded_image"], caption="ğŸ“· ä¸Šä¼ çš„å›¾ç‰‡", width=300)
    
    st.session_state["messages"].append({"role": "user", "content": user_input})

    # 2. è°ƒç”¨ LangGraph
    config = {"configurable": {"thread_id": st.session_state["thread_id"]}}

    # æ˜¾ç¤ºä¸€ä¸ª"æ€è€ƒä¸­"çš„è½¬åœˆåœˆ
    with st.spinner("ğŸ§  Agent æ­£åœ¨æ€è€ƒå¹¶è°ƒç”¨å·¥å…·..."):
        
        # === æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯ ===
        message_content = []
        
        # æ·»åŠ æ–‡æœ¬éƒ¨åˆ†
        message_content.append({"type": "text", "text": user_input})
        
        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œè½¬æ¢ä¸º base64 å¹¶æ·»åŠ 
        if st.session_state["uploaded_image"]:
            image_bytes = st.session_state["uploaded_image"].getvalue()
            image_base64 = base64.b64encode(image_bytes).decode("utf-8")
            
            # è·å–å›¾ç‰‡ MIME ç±»å‹
            image_type = st.session_state["uploaded_image"].type  # å¦‚ "image/png"
            
            message_content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:{image_type};base64,{image_base64}"
                }
            })
        
        # è·å–æœ€ç»ˆå“åº”
        response = graph.invoke(
            {"messages": [HumanMessage(content=message_content)]},
            config=config
        )
        
        # æ¸…ç©ºå·²ä¸Šä¼ çš„å›¾ç‰‡ï¼ˆå‘é€åå°±æ¸…é™¤ï¼‰
        st.session_state["uploaded_image"] = None

        # æå– AI çš„æœ€åä¸€æ¡å›å¤
        ai_message = response["messages"][-1]
        ai_content = ai_message.content

        # ç®€å•å¤„ç†ï¼šå¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œå¼ºåˆ¶è½¬ä¸ºå­—ç¬¦ä¸²
        if not isinstance(ai_content, str):
            ai_content = str(ai_content)

        # === æå–å·¥å…·è°ƒç”¨ä¿¡æ¯ ===
        from langchain_core.messages import ToolMessage
        import datetime
        
        tool_calls_in_turn = []  # æœ¬è½®å¯¹è¯ä¸­çš„å·¥å…·è°ƒç”¨
        messages = response.get("messages", [])
        
        for msg in messages:
            # æŸ¥æ‰¾ AI æ¶ˆæ¯ä¸­çš„ tool_calls
            if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:
                for tc in msg.tool_calls:
                    tool_info = {
                        "name": tc.get("name", "æœªçŸ¥å·¥å…·"),
                        "args": tc.get("args", {}),
                        "id": tc.get("id", ""),
                        "timestamp": datetime.datetime.now().strftime("%H:%M:%S")
                    }
                    tool_calls_in_turn.append(tool_info)
            
            # æŸ¥æ‰¾å·¥å…·è¿”å›çš„ç»“æœ
            if isinstance(msg, ToolMessage):
                # æ‰¾åˆ°å¯¹åº”çš„å·¥å…·è°ƒç”¨å¹¶æ·»åŠ ç»“æœ
                for tc_info in tool_calls_in_turn:
                    if tc_info["id"] == msg.tool_call_id:
                        tc_info["result"] = str(msg.content)[:200]  # æˆªå–å‰200å­—ç¬¦
                        break
        
        # å­˜å‚¨æœ¬è½®å·¥å…·è°ƒç”¨
        if tool_calls_in_turn:
            st.session_state["tool_calls"].append({
                "user_query": user_input,
                "tools": tool_calls_in_turn
            })

        # === æ™ºèƒ½å›æº¯æœºåˆ¶ ===
        # æ—¢ç„¶æœ€åä¸€æ¡å¯èƒ½æ˜¯ç©ºçš„ï¼Œæˆ‘ä»¬å€’åºæŸ¥æ‰¾æœ€åä¸€æ¡æœ‰å†…å®¹çš„æ¶ˆæ¯
        ai_content = "âš ï¸ æœªèƒ½è·å–æœ‰æ•ˆå›ç­”"
        
        for msg in reversed(messages):
            # è·³è¿‡ç”¨æˆ·å‘é€çš„æ¶ˆæ¯
            if isinstance(msg, HumanMessage):
                continue
            # æ‰¾åˆ°æœ‰å†…å®¹çš„æ¶ˆæ¯ï¼ˆæ— è®ºæ˜¯ AI è¯´çš„ï¼Œè¿˜æ˜¯å·¥å…·æŸ¥åˆ°çš„ï¼‰
            if msg.content and str(msg.content).strip():
                ai_content = msg.content
                
                # å¤„ç† content æ˜¯åˆ—è¡¨çš„æƒ…å†µï¼ˆGemini æœ‰æ—¶ä¼šè¿”å›è¿™ç§æ ¼å¼ï¼‰
                if isinstance(ai_content, list):
                    text_parts = []
                    for item in ai_content:
                        if isinstance(item, dict) and "text" in item:
                            text_parts.append(item["text"])
                        elif isinstance(item, str):
                            text_parts.append(item)
                    ai_content = "\n".join(text_parts) if text_parts else str(ai_content)
                
                # å¦‚æœæ˜¯å·¥å…·æ¶ˆæ¯ï¼Œè¯´æ˜ AI å·æ‡’æ²¡å¤è¿°ï¼Œæˆ‘ä»¬å¯ä»¥åŠ ä¸ªæ ‡æ³¨
                if "ToolMessage" in type(msg).__name__:
                    ai_content = f"ã€ç³»ç»Ÿæ£€ç´¢ç»“æœã€‘\n{ai_content}"
                
                # ç¡®ä¿æœ€ç»ˆæ˜¯å­—ç¬¦ä¸²
                if not isinstance(ai_content, str):
                    ai_content = str(ai_content)
                break

    # 3. æ˜¾ç¤º AI å›å¤
    with st.chat_message("assistant"):
        st.write(ai_content)

    st.session_state["messages"].append({"role": "assistant", "content": ai_content})

# ==========================================
# 5. ä¾§è¾¹æ  - å›¾ç‰‡ä¸Šä¼  & å·¥å…·è°ƒç”¨å†å²
# ==========================================
with st.sidebar:
    # --- å›¾ç‰‡ä¸Šä¼ åŒºåŸŸ ---
    st.header("ğŸ–¼ï¸ å›¾ç‰‡ä¸Šä¼ ")
    st.caption("ä¸Šä¼ å›¾ç‰‡è®© AI å¸®ä½ åˆ†æ")
    
    uploaded_file = st.file_uploader(
        "é€‰æ‹©å›¾ç‰‡",
        type=["jpg", "jpeg", "png", "gif", "webp"],
        help="æ”¯æŒ JPGã€PNGã€GIFã€WebP æ ¼å¼"
    )
    
    if uploaded_file:
        st.session_state["uploaded_image"] = uploaded_file
        st.image(uploaded_file, caption="ğŸ“· å¾…å‘é€çš„å›¾ç‰‡", use_container_width=True)
        st.success("âœ… å›¾ç‰‡å·²å‡†å¤‡å¥½ï¼Œè¯·åœ¨ä¸‹æ–¹è¾“å…¥é—®é¢˜åä¸€èµ·å‘é€ï¼")
        
        if st.button("âŒ å–æ¶ˆä¸Šä¼ "):
            st.session_state["uploaded_image"] = None
            st.rerun()
    
    st.divider()
    
    # --- å·¥å…·è°ƒç”¨è¿½è¸ªåŒºåŸŸ ---
    st.header("ğŸ”§ å·¥å…·è°ƒç”¨è¿½è¸ª")
    st.caption("æŸ¥çœ‹ AI åœ¨æ¯æ¬¡å¯¹è¯ä¸­è°ƒç”¨äº†å“ªäº›å·¥å…·")
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²"):
        st.session_state["tool_calls"] = []
        st.rerun()
    
    if not st.session_state["tool_calls"]:
        st.info("æš‚æ— å·¥å…·è°ƒç”¨è®°å½•ï¼Œå¼€å§‹å¯¹è¯åå°†åœ¨è¿™é‡Œæ˜¾ç¤ºã€‚")
    else:
        # å€’åºæ˜¾ç¤ºï¼Œæœ€æ–°çš„åœ¨æœ€ä¸Šé¢
        for i, call_record in enumerate(reversed(st.session_state["tool_calls"])):
            idx = len(st.session_state["tool_calls"]) - i
            with st.expander(f"ğŸ”¹ å¯¹è¯ #{idx}: {call_record['user_query'][:30]}...", expanded=(i == 0)):
                for tool in call_record["tools"]:
                    st.markdown(f"**ğŸ› ï¸ å·¥å…·åç§°:** `{tool['name']}`")
                    st.markdown(f"**â° è°ƒç”¨æ—¶é—´:** {tool['timestamp']}")
                    
                    # æ˜¾ç¤ºå‚æ•°
                    if tool.get("args"):
                        st.markdown("**ğŸ“¥ è¾“å…¥å‚æ•°:**")
                        st.json(tool["args"])
                    
                    # æ˜¾ç¤ºç»“æœ
                    if tool.get("result"):
                        st.markdown("**ğŸ“¤ è¿”å›ç»“æœ:**")
                        st.code(tool["result"], language=None)
                    
                    st.divider()



